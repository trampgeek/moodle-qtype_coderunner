<?xml version="1.0" encoding="UTF-8"?>
<quiz>
<!-- question: 53192  -->
  <question type="coderunner">
    <name>
      <text>PROTOTYPE_DOTNET_C#_METHOD</text>
    </name>
    <questiontext format="html">
      <text><![CDATA[<p><span style="font-size: 0.9375rem;">A prototype for a C# question type that tests a C# method question using the dotnet framework. It runs all tests in a single Jobe run with a single compilation using a Combinator Template Grader. All tests are run serially as a single process, in order to improve performance. Input using standard input is not supported.</span></p>
<p><strong>Contributor</strong>: Mark Stern</p>
<p><strong>Template parameters:</strong></p>
<p><em>total_time_budget:</em> the maximum time allowed (seconds) for the entire testing of the question (the compilation time plus all tests). Should be at least 1 second less than the maximum time limit set by the Jobe server, which is usually 50 secs. Default: 10. </p>
<p></p>
<p><em>warnings_are_errors:</em> true to treat any warning messages as errors. Otherwise, warnings are not displayed to the user unless there are also errors present. Default: true.</p>
<p><em>profiling:</em> true to measure the performance of the build and the run (all tests). Default: false.</p>
<p></p>
<p><em>requiredconstructs:</em> an array of keywords that need to be in the student submission. The check is crude (using an AST would be better), but it at least excludes comments. Default: empty</p>
<p>Example template parameter: <code>{"total_time_budget": 20, "requiredconstructs": ["switch", "case", "break"]}</code></p>
<p></p>
<p><strong style="font-size: 0.9375rem;">Global Extra (Optional):</strong></p>
<p></p>
<p>Any additional code here is run before all the tests</p>
<p><strong style="font-size: 0.9375rem;">WARNINGS</strong><span style="font-size: 0.9375rem;">: </span></p>
<p></p>
<ol>
<li>You will need to have installed the dotnet package on your jobe server (sudo apt-get install dotnet-sdk-8.0).
<ul>
<li>For improved efficiency, you should also install an empty console project at /home/jobe/dotnettemplate; see the template for the required terminal commands.</li>
</ul>
</li>
<li>This question type has had hardly any testing and has never been used in a production environment.</li>
<li>Performance is poor, because it takes around 2 seconds to compile a C# program. Hence, use of this question type in a test or exam is likely to overload the jobe server except with very small classes or when you have a large pool of Jobe servers.</li>
<li>Dotnet does not play well with the usual Jobe 'ulimit' resource limitations, so the memory limit and disklimit (amount of disk i/o) have both been disabled. It is potentially possible for a rogue task to disable the Jobe server by exceeding these limits, although the watchdog timer should kill the job within around 10 seconds and the server should then recover. This theory has not been tested in practice.</li>
</ol>
<p>Caveat emptor!</p>]]></text>
    </questiontext>
    <generalfeedback format="html">
      <text></text>
    </generalfeedback>
    <defaultgrade>1</defaultgrade>
    <penalty>0</penalty>
    <hidden>0</hidden>
    <idnumber></idnumber>
    <coderunnertype>csharpdotnetmethod</coderunnertype>
    <prototypetype>2</prototypetype>
    <allornothing>1</allornothing>
    <penaltyregime>10, 20, ...</penaltyregime>
    <precheck>0</precheck>
    <hidecheck>0</hidecheck>
    <showsource>0</showsource>
    <answerboxlines>18</answerboxlines>
    <answerboxcolumns>100</answerboxcolumns>
    <answerpreload></answerpreload>
    <globalextra></globalextra>
    <useace>1</useace>
    <resultcolumns></resultcolumns>
    <template><![CDATA[""" The template for a question type that compiles and runs a student-submitted
    C#.net method using a combinator template grader that runs all
    test cases in a single compile-and-execute Jobe run.
    All tests are run serially in a single process.
    Input from STDIN is not supported.

    C#.net must have been installed with the command:

    sudo apt-get install dotnet-sdk-8.0

    Performance is also significantly improved (~ 1 sec less build
    time) if a template project is built at location /home/jobe/dotnettemplate
    by commands such as

    sudo bash
    mkdir /home/jobe/dotnettemplate
    cd /home/jobe/dotnettemplate
    dotnet new console --use-program-main
"""
from pathlib import Path
import subprocess
import re
import os
import shutil
import time
import json
from typing import Generator

KNOWN_PARAMS = {'total_time_budget', 'warnings_are_errors',
                'profiling', 'requiredconstructs'}
PARAMS = json.loads("""{{ QUESTION.parameters | json_encode | e('py') }}""")
DEFAULT_TIME_BUDGET = 19
TIME_BUDGET = PARAMS.get('total_time_budget', DEFAULT_TIME_BUDGET)
CSHARP_PROJECT_TEMPLATE = '/home/jobe/dotnettemplate'
NL = "<br>\n"

# Do not use the standard splitter - the angle brackets seem to confuse TWIG.
SPLITTER = "#ab@17943918#"


def strip_comments(text_input: str) -> str:
    """ Strip the comments from the string supplied """
    text_output = re.sub(r'/[*].*?[*]/', '', text_input,
                         flags=re.MULTILINE | re.DOTALL)
    text_output = re.sub(r'//.*', '', text_output)
    return text_output


def pre_run_error(error_message: str) -> dict:
    return {'prologuehtml': f"""
<div class='coderunner-test-results bad'>
  <h3>Pre-run checks failed</h3>
  {error_message}
</div>""", 'fraction': 0.0}


def run_error(error_message: str) -> dict:
    return {'prologuehtml': f"""
<div class='coderunner-test-results bad'>
  <h3>Run failed</h3>
  {error_message}
</div>""", 'fraction': 0.0}


def error_lines(lines: list[str], offset: int) -> Generator[str, None, None]:
    """ Filter out the uninteresting lines
        Tweak the interesting lines so that the line number matches the
        line number in the student submission.
    """
    compiled = re.compile(
        r"(?<=Program.cs\()(\d+)(?=,\d+\): (?:error|warning) CS)")
    for line in lines:
        split_line = compiled.split(line, 1)
        if len(split_line) == 3:
            # It matches the regex
            head, middle, tail = split_line
            # Subtract the number of lines before the student code
            line_number = int(middle)
            if line_number > offset:
                line_number -= offset
            yield f"{head}{line_number}{tail}"


class TestCase:
    def __init__(self, dict_rep):
        """ Construct a testcase from a dictionary representation
            obtained via JSON
        """
        self.testcode = dict_rep['testcode']
        self.stdin = dict_rep['stdin']
        self.expected = dict_rep['expected']
        self.extra = dict_rep['extra']
        self.display = dict_rep['display']
        try:
            self.testtype = int(dict_rep['testtype'])
        except Exception:
            self.testtype = 0
        self.hiderestiffail = bool(int(dict_rep['hiderestiffail']))
        self.useasexample = bool(int(dict_rep['useasexample']))
        self.mark = float(dict_rep['mark'])


def main() -> dict:
    bad_params = set(PARAMS.keys()) - KNOWN_PARAMS
    if bad_params:
        return pre_run_error(
            f"""Error in question!
The following template parameters are unknown: {bad_params}""")

    student_answer = """{{ STUDENT_ANSWER | e('py') }}"""
    required_constructs = PARAMS.get('requiredconstructs', [])
    if required_constructs:
        without_comments = strip_comments(student_answer)
        for construct in required_constructs:
            if construct not in without_comments:
                pre_run_error(
                    "Your program must include at least one "
                    f"{construct} statement.")

    test_cases = [
        TestCase(test) for test in json.loads(
            """{{ TESTCASES | json_encode | e('py') }}"""
        )
    ]
    is_precheck = bool(int("{{ IS_PRECHECK }}"))
    warnaserror = ' --warnaserror' if PARAMS.get('warnings_are_errors',
                                                 False) else ''

    # Now we start the run in earnest.
    t0 = time.perf_counter()

    # Set up a suitable environment
    Path("temp").mkdir(parents=True, exist_ok=True)
    Path('__home__').mkdir(parents=True, exist_ok=True)
    Path('__dotnetclihome__').mkdir(parents=True, exist_ok=True)
    os.environ['HOME'] = '__home__'
    os.environ['DOTNET_CLI_HOME'] = '__dotnetclihome__'

    # Copy or construct a minimal command-line C# project
    path = Path(CSHARP_PROJECT_TEMPLATE)
    if path.is_dir():
        for item in path.iterdir():
            if item.is_dir():
                shutil.copytree(item, Path.cwd() / item.name)
            else:
                shutil.copy2(item, Path.cwd())
    else:
        result = subprocess.run(
            "dotnet new console --use-program-main".split(),
            capture_output=True, text=True
        )
        if result.returncode != 0:
            return pre_run_error(
                f"dotnet new command failed: {result.stdout}\n{result.stderr}"
            )

    # For time profiling of the various steps
    times = {'New': time.perf_counter()}

    # Write the student code to a file prog.cs
    with open("Program.cs", "w") as src:
        src.write("""
using System;
public class Program
{
""")
    # Count the lines before the student answer, so that we can fix
    # error messages to make them more friendly to the student
    with open(r"Program.cs", 'r') as src:
        student_answer_offset = sum(1 for line in src)
    with open("Program.cs", "a") as src:
        src.write(student_answer)
        src.write("""
    public static void Main(string[] args)
    {
        {{ QUESTION.globalextra }}
{% for TEST in TESTCASES %}
        {
            {{ TEST.testcode }};
        }
{% if not loop.last %}
""")
        # f-strings and TWIG do not play nicely together
        src.write('Console.WriteLine("' + SPLITTER + '");')
        src.write("""
{% endif %}
{% endfor %}
    }
}
""")

    # Build the project
    result = subprocess.run(f"""dotnet build{warnaserror} --verbosity quiet
                                --nologo -consoleloggerparameters:NoSummary
                                --no-restore""".split(),
                            capture_output=True, text=True)
    times['Build'] = time.perf_counter()

    # Prepare to construct the grader response dictionary, putting any compile
    # errors into the dictionary, formatted according to whether or not this
    # is a precheck.
    compile_ok = result.returncode == 0
    if not compile_ok:
        error_output = result.stderr + result.stdout
        error_message = f"""<pre>\n{NL.join(
            error_lines(error_output.splitlines(),
                        student_answer_offset))}</pre>"""

    if is_precheck:
        if compile_ok:
            return {'prologuehtml': """<p class='precheckresult'>
  Passed 🙂
</p>""", 'fraction': 1}
        else:
            return {'prologuehtml': f"""<p class='precheckresult'>
  Failed, as follows.
</p>
{error_message}""", 'fraction': 0.0}

    # Not a precheck. Either report any compile errors or run all tests.
    if not compile_ok:
        return pre_run_error(error_message)

    # If compile succeeded and it's not a precheck run all the tests.
    hiding_rest = False
    all_passed = True
    t_remaining = TIME_BUDGET - (time.perf_counter() - t0)
    try:
        output = subprocess.check_output(
            "dotnet run --no-build --nologo".split(),
            timeout=t_remaining,  # Ensure we don't get killed by Jobe.
            text=True
        ).rstrip()
    except subprocess.TimeoutExpired:
        return run_error('*** TIMEOUT ***\nFurther testing aborted.')
    except subprocess.CalledProcessError as e:
        message = f'Task failed with signal {-e.returncode}'
        if e.output:
            message = e.output + '\n' + message
            message += '\n*** Further testing has been aborted ***'
        return run_error(message)

    times[f'Run Tests'] = time.perf_counter()

    # No exceptions during run
    outputs = output.split(SPLITTER + "\n")
    if len(outputs) > len(test_cases):
        return run_error("There is too much output")
    if len(outputs) < len(test_cases):
        return run_error("There is not enough output")

    result_table = [['iscorrect', 'ishidden', 'Test', 'Expected', 'Got']]
    for test, output in zip(test_cases, outputs):
        is_correct = output.rstrip() == test.expected.rstrip()
        if not is_correct:
            all_passed = False
        is_hidden = any((hiding_rest,
                         test.display == 'HIDE',
                         test.display == 'HIDE_IF_SUCCEED' and is_correct,
                         test.display == 'HIDE_IF_FAIL' and not is_correct))
        result_table.append([is_correct, is_hidden, test.testcode,
                             test.expected, output])
        if test.hiderestiffail and not is_correct:
            # Need to hide rest of tests from student
            # but continue for benefit of teachers.
            hiding_rest = True

    grader_response = {
        'testresults': result_table,
        'fraction': 1.0 if all_passed else 0.0
    }

    # Add per-step time profiling if profiling template parameter is true.
    if PARAMS['profiling']:
        t_last = t0
        time_message = ''
        for label, t in times.items():
            time_message += f'{label}: {t - t_last:.2f} secs<br>'
            t_last = t
        grader_response['epiloguehtml'] = f"<h5>Step execution times</h5><p>{time_message}</p>"

    return grader_response


print(json.dumps(main()))
]]></template>
    <iscombinatortemplate>1</iscombinatortemplate>
    <allowmultiplestdins>1</allowmultiplestdins>
    <answer></answer>
    <validateonsave>0</validateonsave>
    <testsplitterre><![CDATA[|#<ab@17943918#@>#\n|ms]]></testsplitterre>
    <language>python3</language>
    <acelang>cs</acelang>
    <sandbox></sandbox>
    <grader>TemplateGrader</grader>
    <cputimelimitsecs>8</cputimelimitsecs>
    <memlimitmb>0</memlimitmb>
    <sandboxparams><![CDATA[{"numprocs":1000,"disklimit":2000000000}]]></sandboxparams>
    <templateparams><![CDATA[{
    "total_time_budget": 10,
    "warnings_are_errors": true,
    "profiling": false
}]]></templateparams>
    <hoisttemplateparams>0</hoisttemplateparams>
    <extractcodefromjson>1</extractcodefromjson>
    <templateparamslang>twig</templateparamslang>
    <templateparamsevalpertry>0</templateparamsevalpertry>
    <templateparamsevald><![CDATA[{
    "total_time_budget": 10,
    "warnings_are_errors": true,
    "profiling": false
}]]></templateparamsevald>
    <twigall>0</twigall>
    <uiplugin>ace</uiplugin>
    <uiparameters></uiparameters>
    <attachments>0</attachments>
    <attachmentsrequired>0</attachmentsrequired>
    <maxfilesize>0</maxfilesize>
    <filenamesregex></filenamesregex>
    <filenamesexplain></filenamesexplain>
    <displayfeedback>1</displayfeedback>
    <giveupallowed>0</giveupallowed>
    <prototypeextra></prototypeextra>
    <testcases>
    </testcases>
  </question>

</quiz>